import cv2
import time
from PIL import Image
from transformers import Blip2Processor, Blip2ForConditionalGeneration
import torch

print("üü¢ Iniciando sistema com BLIP-2")

# Carregar modelo e processador BLIP-2 (pesado!)
processor = Blip2Processor.from_pretrained("Salesforce/blip2-opt-2.7b")
model = Blip2ForConditionalGeneration.from_pretrained(
    "Salesforce/blip2-opt-2.7b",
    device_map="auto",  # Tenta usar GPU automaticamente
    torch_dtype=torch.float16
)

# Fun√ß√£o para capturar imagem
def capturar_imagem():
    cam = cv2.VideoCapture(0)
    time.sleep(2)
    ret, frame = cam.read()
    if not ret:
        print("‚ùå Erro ao acessar a webcam.")
        cam.release()
        return None
    img_path = "frame.jpg"
    cv2.imwrite(img_path, frame)
    cam.release()
    print("üì∑ Imagem salva:", img_path)
    return img_path

# Fun√ß√£o de an√°lise com perguntas
def detectar_dor_blip2(imagem_path):
    image = Image.open(imagem_path).convert("RGB")
    
    perguntas = [
        "Is the person in pain?",
        "Is the person injured?",
        "Is the person suffering?",
        "Does the person look sick?"
    ]
    
    for pergunta in perguntas:
        inputs = processor(images=image, text=pergunta, return_tensors="pt").to("cuda" if torch.cuda.is_available() else "cpu", torch.float16)
        outputs = model.generate(**inputs)
        resposta = processor.tokenizer.decode(outputs[0], skip_special_tokens=True)
        print(f"‚ùì {pergunta}")
        print(f"‚û°Ô∏è Resposta: {resposta}\n")
        
        if "yes" in resposta.lower():
            print("‚ö†Ô∏è ALERTA: Dor detectada!")
            return
    
    print("‚úÖ Aparentemente, a pessoa est√° bem.")

# Execu√ß√£o
print("üì∏ Capturando imagem...")
imagem = capturar_imagem()
if imagem:
    detectar_dor_blip2(imagem)

# üì¶ Instalar os pacotes necess√°rios (no terminal):
# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
# pip install transformers opencv-python pillow